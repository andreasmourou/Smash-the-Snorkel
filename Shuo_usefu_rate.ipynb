{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Hey I've added this so we can see properly SQL Views from Spark (Simon)\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First: filter the restaurant\n",
    "biz_df = sqlContext.read.json(\"original_data/business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "|             address|          attributes|         business_id|          categories|              city|               hours|is_open|     latitude|      longitude|                name|postal_code|review_count|stars|state|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "|30 Eglinton Avenue W|[,, u'full_bar', ...|QXAEGFB4oINsVuTFx...|Specialty Food, R...|       Mississauga|[9:0-1:0, 9:0-0:0...|      1|43.6054989743|  -79.652288909|Emerald Chinese R...|    L5R 3E7|         128|  2.5|   ON|\n",
      "|10110 Johnston Rd...|[,, u'beer_and_wi...|gnKjwL_1w79qoiV3I...|Sushi Bars, Resta...|         Charlotte|[17:30-22:0, 17:3...|      1|    35.092564|     -80.859132|Musashi Japanese ...|      28210|         170|  4.0|   NC|\n",
      "|2450 E Indian Sch...|[,, u'none', {'ro...|1Dfx3zM-rW4n-31Ke...|Restaurants, Brea...|           Phoenix|[7:0-1:0, 7:0-0:0...|      1|   33.4951941|   -112.0285876|           Taco Bell|      85016|          18|  3.0|   AZ|\n",
      "|     5981 Andrews Rd|[,, u'none', None...|fweCYi8FmbJXHCqLn...|Italian, Restaura...|Mentor-on-the-Lake|[10:0-1:0, 10:0-0...|      1|     41.70852|     -81.359556|       Marco's Pizza|      44060|          16|  4.0|   OH|\n",
      "|1775 E Tropicana ...|[,, u'full_bar', ...|PZ-LZzSlhSe9utkQY...|Restaurants, Italian|         Las Vegas|                null|      0|   36.1000163|   -115.1285285|Carluccio's Tivol...|      89119|          40|  4.0|   NV|\n",
      "|Center Core - Foo...|[,,, {'touristy':...|1RHY4K3BD22FK7Cff...|Sandwiches, Salad...|        Pittsburgh|                null|      1|40.4961769456| -80.2460112364|      Marathon Diner|      15231|          35|  4.0|   PA|\n",
      "|6055 E Lake Mead ...|[,, u'beer_and_wi...|tstimHoMcYbkSC4eB...|Mexican, Restaura...|         Las Vegas|[10:0-21:0, 11:0-...|      1|   36.1956146|   -115.0405289|Maria's Mexican R...|      89156|         184|  4.5|   NV|\n",
      "| 1170 Queen Street W|[,,,,,,, True,,, ...|NDuUMJfrWk52RA-H-...|Juice Bars & Smoo...|           Toronto|[8:0-21:0, 8:0-21...|      1|   43.6428886|    -79.4254291|      Bolt Fresh Bar|    M6J 1J5|          57|  3.0|   ON|\n",
      "| 1051 Bloor Street W|[,, u'full_bar', ...|SP_YXIEwkFPPl_9an...|Restaurants, Nigh...|           Toronto|[9:0-2:0,, 10:0-2...|      0|   43.6604937|     -79.432099|The Steady Cafe &...|    M6H 1M4|          29|  3.5|   ON|\n",
      "|  6401 Morrison Blvd|[,, u'full_bar',,...|BvYU3jvGd0TJ7IyZd...|Sandwiches, Itali...|         Charlotte|[11:0-23:0, 11:0-...|      0|    35.156338|     -80.831878|   Manzetti's Tavern|      28211|          16|  3.5|   NC|\n",
      "|   2825 32 Avenue NE|[,,,,,,,,,, {'gar...|e_EMySqP0uwlVZfd8...|Chinese, Dim Sum,...|           Calgary|                null|      0|   51.0811622|   -113.9934738|        Pearl Garden|        T1Y|           4|  2.0|   AB|\n",
      "|  582 College Street|[,, u'full_bar', ...|mlHC2XcU9Bows6cnY...|Restaurants, Brea...|           Toronto|[18:0-2:0,, 18:0-...|      0|   43.6554201|    -79.4133518|  Mad Crush Wine Bar|    M6G 1B3|           9|  4.0|   ON|\n",
      "|6432 E Independen...|[,, u'full_bar', ...|_J_x_RaYTqAqAuCwg...|Coffee & Tea, Hoo...|         Charlotte|[12:30-2:0,, 12:3...|      0|    35.172028|     -80.746801|         Kabob House|      28212|          15|  3.0|   NC|\n",
      "|17205 Leslie Stre...|[,, u'none', {'to...|6l00a9Gkxkcp_y-GP...|Fish & Chips, Res...|         Newmarket|                null|      1|   44.0587654|    -79.4291147|    J's Fish & Chips|    L3Y 8Y8|          12|  4.5|   ON|\n",
      "|       4606 Penn Ave|[,, u'full_bar', ...|dQj5DLZjeDK3KFysh...|Nightlife, Bars, ...|        Pittsburgh|[17:0-0:0,, 17:0-...|      1|   40.4656937|    -79.9493238|              Apteka|      15224|         242|  4.5|   PA|\n",
      "|3085 Hurontario S...|[,, 'none', {'rom...|9UTpmQ4OhX5jNFUIu...| Restaurants, Korean|       Mississauga|[11:0-22:0, 11:0-...|      1|    43.582262|     -79.618858|Buk Chang Dong So...|        L5A|         103|  4.0|   ON|\n",
      "|       436 Market St|[,, 'none', {'tou...|v-scZMU6jhnmV955R...|Japanese, Sushi B...|        Pittsburgh|[11:0-20:0, 11:0-...|      1|    40.441062|     -80.002126|   No. 1 Sushi Sushi|      15222|         106|  4.5|   PA|\n",
      "|6125 Spring Mount...|[,, u'none', {'ro...|kANF0dbeoW34s2vwh...|Fast Food, Food, ...|         Las Vegas|                null|      0|   36.1250311|   -115.2256202|         Dairy Queen|      89146|          33|  2.0|   NV|\n",
      "|825 Commonwealth Ave|[,, u'full_bar', ...|KFbUQ-RR2UOV62Ep7...|American (Traditi...|      West Mifflin|[11:0-2:0,, 11:0-...|      1|    40.376674|      -79.88248|Westwood Bar & Grill|      15122|           5|  3.0|   PA|\n",
      "|13843 N Tatum Blv...|[,, 'beer_and_win...|44YFU284Z3KDEy25Q...|Chinese, Restaurants|           Phoenix|[11:0-21:30, 11:0...|      1|33.6130201898|-111.9770356779|Nee House Chinese...|      85032|         269|  3.5|   AZ|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "biz_df.createOrReplaceTempView('biz_table')\n",
    "biz_res = sqlContext.sql('SELECT * FROM biz_table WHERE categories LIKE \\'%Restaurants%\\'')\n",
    "biz_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_res.createOrReplaceTempView('biz_res_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_res(parent,filename,key):\n",
    "    df = sqlContext.read.json(\"original_data/\"+filename)\n",
    "    table_name=filename[:-5]+'_table'\n",
    "    df.createOrReplaceTempView(filename[:-5]+'_table')\n",
    "    sqlquery = 'SELECT c.* FROM {} c LEFT JOIN {} b ON c.{} = b.{} WHERE b.{} IS NOT NULL'.format(table_name,parent,key,key,key)\n",
    "    print(sqlquery)\n",
    "    df_res=sqlContext.sql(sqlquery)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT c.* FROM checkin_table c LEFT JOIN biz_res_table b ON c.business_id = b.business_id WHERE b.business_id IS NOT NULL\n",
      "SELECT c.* FROM review_table c LEFT JOIN biz_res_table b ON c.business_id = b.business_id WHERE b.business_id IS NOT NULL\n",
      "SELECT c.* FROM tip_table c LEFT JOIN review_res_table b ON c.user_id = b.user_id WHERE b.user_id IS NOT NULL\n",
      "SELECT c.* FROM user_table c LEFT JOIN review_res_table b ON c.user_id = b.user_id WHERE b.user_id IS NOT NULL\n"
     ]
    }
   ],
   "source": [
    "checkin_res = filter_res('biz_res_table','checkin.json','business_id')\n",
    "review_res = filter_res('biz_res_table','review.json','business_id')\n",
    "review_res.createOrReplaceTempView('review_res_table')\n",
    "tip_res = filter_res('review_res_table','tip.json','user_id') #since tip is on individual level, match them with users\n",
    "user_res = filter_res('review_res_table','user.json','user_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample  business into dev_set and test_set\n",
    "import pyspark.sql.functions as f\n",
    "review_res = review_res.withColumn('index_1', f.monotonically_increasing_id())\n",
    "review_res.createOrReplaceTempView('review_res_table')\n",
    "sqlquery = 'SELECT * FROM review_res_table ORDER BY RAND(42) LIMIT {}'.format(1000)\n",
    "review_sample = sqlContext.sql(sqlquery)\n",
    "review_sample.createOrReplaceTempView('review_sample_table')\n",
    "\n",
    "sqlquery = 'SELECT a.* FROM review_res_table a LEFT JOIN review_sample_table b ON a.index_1 = b.index_1 WHERE b.index_1 IS NULL '\n",
    "review_train = sqlContext.sql(sqlquery)\n",
    "review_train_all = sqlContext.sql(sqlquery)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 500 into dev_set and 500 into test_set\n",
    "from pyspark.sql.functions import desc\n",
    "review_sample = review_sample.withColumn('index_2', f.monotonically_increasing_id())\n",
    "review_dev = review_sample.limit(500)\n",
    "review_test = review_sample.sort(desc(\"index_2\")).limit(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train = review_train_all.limit(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biz_useful=biz_res.select('business_id','review_count')\n",
    "ind_useful=review_res.select('user_id','useful','business_id') #aggregate ind\n",
    "mapped_test = ind_useful.rdd.map(lambda x: (x[0],x[1]))\n",
    "ind_total_useful = mapped_test.reduceByKey(lambda a,b:a+b)\n",
    "mapped_test = ind_useful.rdd.map(lambda x: (x[0],1))\n",
    "ind_total_review =  mapped_test.reduceByKey(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+-------------+-------------------+\n",
      "|             user_id|total_useful|             user_id|total_reviews|         avg_useful|\n",
      "+--------------------+------------+--------------------+-------------+-------------------+\n",
      "|-0Ji0nOyFe-4yo8BK...|           0|-0Ji0nOyFe-4yo8BK...|            1|                0.0|\n",
      "|-1KKYzibGPyUX-Mwk...|           1|-1KKYzibGPyUX-Mwk...|            1|                1.0|\n",
      "|-1zQA2f_syMAdA04P...|           0|-1zQA2f_syMAdA04P...|            2|                0.0|\n",
      "|-2Pb5d2WBPtbyGT_b...|           0|-2Pb5d2WBPtbyGT_b...|            1|                0.0|\n",
      "|-3bsS2i9xqjNnIA1f...|           3|-3bsS2i9xqjNnIA1f...|            2|                1.5|\n",
      "|-3i9bhfvrM3F1wsC9...|          22|-3i9bhfvrM3F1wsC9...|            9| 2.4444444444444446|\n",
      "|-47g7LR58tpHlm7Bm...|           0|-47g7LR58tpHlm7Bm...|            1|                0.0|\n",
      "|-4Anvj46CWf57KWI9...|           1|-4Anvj46CWf57KWI9...|            1|                1.0|\n",
      "|-4xyc3OgPwrLshmqH...|           0|-4xyc3OgPwrLshmqH...|            1|                0.0|\n",
      "|-55DgUo52I3zW9Rxk...|           1|-55DgUo52I3zW9Rxk...|           19|0.05263157894736842|\n",
      "|-7JSlmBJKUQwREG_y...|           4|-7JSlmBJKUQwREG_y...|            5|                0.8|\n",
      "|-7V6r0PLuBlFVjbLJ...|           0|-7V6r0PLuBlFVjbLJ...|            1|                0.0|\n",
      "|-897i_JdWyDsXGUa8...|           0|-897i_JdWyDsXGUa8...|            1|                0.0|\n",
      "|-8_yETBp70WiqqN-A...|           0|-8_yETBp70WiqqN-A...|            3|                0.0|\n",
      "|-9aO6i4fmPWrLyW4i...|           0|-9aO6i4fmPWrLyW4i...|            1|                0.0|\n",
      "|-9da1xk7zgnnfO1uT...|         266|-9da1xk7zgnnfO1uT...|           29|  9.172413793103448|\n",
      "|-9v-3PG1-NAefOd2R...|           1|-9v-3PG1-NAefOd2R...|            2|                0.5|\n",
      "|-AkSsUVQ0CCBe5qsK...|           1|-AkSsUVQ0CCBe5qsK...|            1|                1.0|\n",
      "|-BUamlG3H-7yqpAl1...|           0|-BUamlG3H-7yqpAl1...|            2|                0.0|\n",
      "|-CGdueQKCHM_KnHxO...|           1|-CGdueQKCHM_KnHxO...|            1|                1.0|\n",
      "+--------------------+------------+--------------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+------------+\n",
      "|         business_id|stars|review_count|\n",
      "+--------------------+-----+------------+\n",
      "|QXAEGFB4oINsVuTFx...|  2.5|         128|\n",
      "|gnKjwL_1w79qoiV3I...|  4.0|         170|\n",
      "|1Dfx3zM-rW4n-31Ke...|  3.0|          18|\n",
      "|fweCYi8FmbJXHCqLn...|  4.0|          16|\n",
      "|PZ-LZzSlhSe9utkQY...|  4.0|          40|\n",
      "|1RHY4K3BD22FK7Cff...|  4.0|          35|\n",
      "|tstimHoMcYbkSC4eB...|  4.5|         184|\n",
      "|NDuUMJfrWk52RA-H-...|  3.0|          57|\n",
      "|SP_YXIEwkFPPl_9an...|  3.5|          29|\n",
      "|BvYU3jvGd0TJ7IyZd...|  3.5|          16|\n",
      "|e_EMySqP0uwlVZfd8...|  2.0|           4|\n",
      "|mlHC2XcU9Bows6cnY...|  4.0|           9|\n",
      "|_J_x_RaYTqAqAuCwg...|  3.0|          15|\n",
      "|6l00a9Gkxkcp_y-GP...|  4.5|          12|\n",
      "|dQj5DLZjeDK3KFysh...|  4.5|         242|\n",
      "|9UTpmQ4OhX5jNFUIu...|  4.0|         103|\n",
      "|v-scZMU6jhnmV955R...|  4.5|         106|\n",
      "|kANF0dbeoW34s2vwh...|  2.0|          33|\n",
      "|KFbUQ-RR2UOV62Ep7...|  3.0|           5|\n",
      "|44YFU284Z3KDEy25Q...|  3.5|         269|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to spark data frame\n",
    "df_ind_total_useful = ind_total_useful.toDF([\"user_id\", \"total_useful\"])\n",
    "df_ind_total_review = ind_total_review.toDF([\"user_id\", \"total_reviews\"])\n",
    "df_ind_useful = df_ind_total_useful.join(df_ind_total_review, df_ind_total_useful.user_id == df_ind_total_review.user_id)\n",
    "df_ind_useful = df_ind_useful.withColumn('avg_useful' , df_ind_useful.total_useful/df_ind_useful.total_reviews)\n",
    "df_ind_useful.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biz_useful=df_biz_useful.toPandas()\n",
    "df_ind_useful=df_ind_useful.toPandas()\n",
    "df_ind_useful = df_ind_useful.loc[:,~df_ind_useful.columns.duplicated()]\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from snorkel.labeling import PandasLFApplier,LFAnalysis\n",
    "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
    "pd_dev = pd.read_csv(\"review_dev_labelled.csv\",header=0, index_col=0)\n",
    "df_dev = spark.createDataFrame(pd_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1.021650\n",
       "1    1.457707\n",
       "Name: avg_useful, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0     8.0\n",
       "1    10.0\n",
       "Name: total_reviews, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    52.6\n",
       "1    86.0\n",
       "Name: total_reviews, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Threshold Analysis: Low Useful Rate\n",
    "temp=pd_dev.merge(df_ind_useful, on= 'user_id', how='left')\n",
    "temp.groupby('label')['avg_useful'].agg('mean')\n",
    "def q(x):\n",
    "            return x.quantile(0.85)\n",
    "temp.groupby('label')['total_reviews'].agg('median')\n",
    "temp.groupby('label')['total_reviews'].agg(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to apply Labeling function\n",
    "import pyspark.sql.functions as F\n",
    "from snorkel.labeling import LabelModel\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from snorkel.labeling import ,LFAnalysis\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from pyspark.sql import Row\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "#from snorkel.labeling.lf.nlp_spark import spark_nlp_labeling_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "ABSTAIN = -1\n",
    "NEGATIVE = 0\n",
    "POSITIVE = 1\n",
    "\n",
    "@labeling_function()\n",
    "def high_useful(x):\n",
    "    return POSITIVE if x.useful > 8 else ABSTAIN\n",
    "\n",
    "dict_biz_useful = dict(zip(df_biz_useful.business_id, df_biz_useful.stars))\n",
    "\n",
    "@labeling_function(resources=dict(dict_biz_useful=dict_biz_useful))\n",
    "def high_useful_biz(x,dict_biz_useful):\n",
    "    if x.business_id!='#NAME?':\n",
    "        a = dict_biz_useful[x.business_id]\n",
    "    else:\n",
    "        a = 0\n",
    "    return POSITIVE if (x.useful > 8 and a < x.useful ) else ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_info = zip(df_ind_useful.avg_useful, df_ind_useful.total_reviews)\n",
    "dict_ind_useful = dict(zip(df_ind_useful.user_id, com_info ))\n",
    "@labeling_function(resources=dict(dict_biz_useful=dict_biz_useful))\n",
    "def high_useful_ind(x,dict_ind_useful):\n",
    "    if x.userid_id!='#NAME?':\n",
    "        if x.user_id in dict_ind_useful.keys():\n",
    "            a = dict_ind_useful[x.user_id][0]\n",
    "            b = dict_ind_useful[x.user_id][1]\n",
    "        else:\n",
    "            a = 0\n",
    "            b = 0 \n",
    "    else:\n",
    "        a = 0\n",
    "        b = 0\n",
    "    return NEGATIVE if (x.useful > a) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(dict_ind_useful=dict_ind_useful))\n",
    "def picky_indiv(x,dict_ind_useful):\n",
    "    if x.user_id!='#NAME?':\n",
    "        if x.user_id in dict_ind_useful.keys():\n",
    "            a = dict_ind_useful[x.user_id][0]\n",
    "            b = dict_ind_useful[x.user_id][1]\n",
    "        else:\n",
    "            a = 0\n",
    "            b = 0 \n",
    "    else:\n",
    "        a = 0\n",
    "        b = 0\n",
    "    return NEGATIVE if a < 1 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>picky_indiv</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "      <td>181</td>\n",
       "      <td>0.392617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "picky_indiv  0      [1]     0.596       0.0        0.0      117        181   \n",
       "\n",
       "             Emp. Acc.  \n",
       "picky_indiv   0.392617  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs = []\n",
    "applier = SparkLFApplier(lfs)\n",
    "L_dev = applier.apply(df_dev.rdd)\n",
    "g_label =np.array(df_dev.select('label').collect())\n",
    "LFAnalysis(L_dev, lfs).lf_summary(g_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high_useful</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_useful_biz</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picky_indiv</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181</td>\n",
       "      <td>117</td>\n",
       "      <td>0.607383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "high_useful      0      [1]     0.012     0.012        0.0        4   \n",
       "high_useful_biz  1      [1]     0.012     0.012        0.0        4   \n",
       "picky_indiv      2      [0]     0.596     0.000        0.0      181   \n",
       "\n",
       "                 Incorrect  Emp. Acc.  \n",
       "high_useful              2   0.666667  \n",
       "high_useful_biz          2   0.666667  \n",
       "picky_indiv            117   0.607383  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build label matrix\n",
    "import re\n",
    "lfs = [high_useful,high_useful_biz,picky_indiv]\n",
    "applier = SparkLFApplier(lfs)\n",
    "L_dev = applier.apply(df_dev.rdd)\n",
    "g_label =np.array(df_dev.select('label').collect())\n",
    "LFAnalysis(L_dev, lfs).lf_summary(g_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
