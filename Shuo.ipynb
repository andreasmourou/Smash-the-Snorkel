{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from nltk) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"review_dev_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                           Non-Null Count  Dtype  \n",
      "---  ------                                           --------------  -----  \n",
      " 0   #                                                500 non-null    int64  \n",
      " 1   business_id                                      500 non-null    object \n",
      " 2   cool                                             500 non-null    int64  \n",
      " 3   date                                             500 non-null    object \n",
      " 4   funny                                            500 non-null    int64  \n",
      " 5   review_id                                        500 non-null    object \n",
      " 6   stars                                            500 non-null    int64  \n",
      " 7   text                                             500 non-null    object \n",
      " 8   useful                                           500 non-null    int64  \n",
      " 9   user_id                                          500 non-null    object \n",
      " 10  index_1                                          500 non-null    float64\n",
      " 11  index_2                                          500 non-null    int64  \n",
      " 12  label                                            497 non-null    float64\n",
      " 13  Label 1 if text contains a suggestion/complaint  500 non-null    int64  \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import development set and drop unessesaty columns\n",
    "df=df.reset_index()\n",
    "df=df.drop([\"index_1\",\"index_2\",\"business_id\",\"cool\",\"date\",\"funny\",\"label\"], axis=1)\n",
    "df=df.rename(columns={\"Label 1 if text contains a suggestion/complaint\": \"label\"})\n",
    "df=df.drop([\"#\",\"review_id\",\"user_id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   500 non-null    int64 \n",
      " 1   stars   500 non-null    int64 \n",
      " 2   text    500 non-null    object\n",
      " 3   useful  500 non-null    int64 \n",
      " 4   label   500 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a great outside poolside place for delightful and imaginative drinks located at the wild horse pass resort and spa in chandler az also provides a variety of food items to satisfy your hunger fantastic view of the surrounding mountains with large pool area for adults and children pool chairs have a flag system that you can raise for service so no matter where you sit you never have to leave your seat for food or drink the separate eating area is covered and the birds that beg for food are not afraid of humans after a long flight this is the place to sit back enjoy the scenery and take in a drink or three staff is the best only draw back for me is like the places in miami the gratuity is added to your check it is a shame that businesses feel this has to be done for their workers because some people leave little or no tip for the servers if you don t wish to tip there is always the fast food drive thru we enjoyed the drinks food and especially the staff we are hosting a family get together here this weekend '"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    #remove tags\n",
    "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    " \n",
    "df['text'] = df['text'].apply(lambda x:pre_process(x))\n",
    " \n",
    "#show the second 'text' just for fun\n",
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into 0 or 1 \n",
    "one=df[df[\"label\"]==1]\n",
    "zero=df[df[\"label\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words\"\"\"\n",
    "    with open(stop_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords=f.readlines()\n",
    "        stop_set=set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"stopwords.txt\")\n",
    "\n",
    "#get the text column\n",
    "docs=one[\"text\"].tolist()\n",
    "\n",
    "#create a vocabulary of words,\n",
    "#ignore words that appear in 85% of documents,\n",
    "#eliminate stop words\n",
    "a=one[\"text\"].tolist()\n",
    "cv=CountVectorizer(max_df=1)\n",
    "word_count_vector=cv.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 2173)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['108', 'abaft', 'abafter', 'abaftest', 'about', 'abouter', 'aboutest', 'above', 'abover', 'abovest', 'accordingly', 'aer', 'aest', 'afore', 'after', 'afterer', 'afterest', 'afterward', 'afterwards', 'again', 'against', 'aid', 'ain', 'albeit', 'all', 'aller', 'allest', 'alls', 'allyou', 'almost', 'along', 'alongside', 'already', 'also', 'although', 'always', 'amid', 'amidst', 'among', 'amongst', 'an', 'and', 'andor', 'anear', 'anent', 'another', 'ansi', 'ansicpg1252', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anywhere', 'apart', 'aparter', 'apartest', 'appear', 'appeared', 'appearing', 'appears', 'appropriate', 'appropriated', 'appropriater', 'appropriates', 'appropriatest', 'appropriating', 'are', 'ares', 'around', 'as', 'ases', 'aside', 'asides', 'aslant', 'astraddle', 'astraddler', 'astraddlest', 'astride', 'astrider', 'astridest', 'at', 'athwart', 'atop', 'atween', 'aught', 'aughts', 'available', 'availabler', 'availablest', 'awfully', 'bar', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'becominger', 'becomingest', 'becomings', 'been', 'before', 'beforehand', 'beforehander', 'beforehandest', 'behind', 'behinds', 'being', 'below', 'beneath', 'beside', 'besides', 'better', 'bettered', 'bettering', 'betters', 'between', 'betwixt', 'beyond', 'bist', 'blockquote', 'blue109', 'blue255', 'blue26', 'blue34', 'both', 'brdrnil', 'but', 'buts', 'by', 'byandby', 'c100000', 'c10588', 'c12157', 'c13725', 'c14118', 'c16078', 'c18039', 'c29804', 'c50196', 'can', 'cannot', 'canst', 'cant', 'canted', 'cantest', 'canting', 'cants', 'cell', 'cellx4320', 'cellx8640', 'cer', 'certain', 'certainer', 'certainest', 'cest', 'cf2', 'cf5', 'chez', 'circa', 'clbrdrb', 'clbrdrl', 'clbrdrr', 'clbrdrt', 'clftswidth3', 'clminw1000', 'clmrg', 'clpadl200', 'clpadr200', 'clshdrawnil', 'clvertalt', 'clwwidth1000', 'clwwidth2379', 'co', 'cocoartf1561', 'cocoasubrtf610', 'code', 'colortbl', 'come', 'comeon', 'comeons', 'concerning', 'concerninger', 'concerningest', 'consequently', 'considering', 'consolas', 'could', 'couldst', 'cssrgb', 'cum', 'dday', 'ddays', 'deftab720', 'describe', 'described', 'describes', 'describing', 'despite', 'despited', 'despites', 'despiting', 'did', 'different', 'differenter', 'differentest', 'do', 'doe', 'does', 'doing', 'doings', 'done', 'doner', 'dones', 'donest', 'dos', 'dost', 'doth', 'downs', 'downward', 'downwarder', 'downwardest', 'downwards', 'during', 'each', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'ere', 'et', 'etc', 'even', 'evened', 'evenest', 'evens', 'evenser', 'evensest', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'except', 'excepted', 'excepting', 'excepts', 'exes', 'expandedcolortbl', 'expnd0', 'expndtw0', 'f0', 'fact', 'facts', 'failing', 'failings', 'fcharset0', 'few', 'fewer', 'fewest', 'figupon', 'figuponed', 'figuponing', 'figupons', 'five', 'fnil', 'followthrough', 'fonttbl', 'foo', 'for', 'forby', 'forbye', 'fore', 'forer', 'fores', 'forever', 'former', 'formerer', 'formerest', 'formerly', 'formers', 'fornenst', 'forwhy', 'four', 'fourscore', 'frae', 'from', 'fs', 'fs24', 'further', 'furthered', 'furtherer', 'furtherest', 'furthering', 'furthermore', 'furthers', 'gaph', 'get', 'gets', 'getting', 'go', 'gone', 'good', 'got', 'gotta', 'gotten', 'green109', 'green23', 'green255', 'green31', 'gt', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'had', 'hadst', 'hae', 'hardly', 'has', 'hast', 'hath', 'have', 'haves', 'having', 'he', 'hence', 'her', 'hereafter', 'hereafters', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'hither', 'hitherer', 'hitherest', 'hoo', 'hoos', 'how', 'howbeit', 'howdoyoudo', 'however', 'huh', 'humph', 'idem', 'idemer', 'idemest', 'ie', 'if', 'ifs', 'immediate', 'immediately', 'immediater', 'immediatest', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'indicating', 'info', 'information', 'insofar', 'instead', 'intbl', 'into', 'inward', 'inwarder', 'inwardest', 'inwards', 'is', 'it', 'itap1', 'its', 'itself', 'kerning0', 'lastrow', 'latter', 'latterer', 'latterest', 'latterly', 'latters', 'layabout', 'layabouts', 'less', 'lest', 'li', 'lot', 'lots', 'lotted', 'lotting', 'lt', 'main', 'make', 'many', 'margl1440', 'margr1440', 'mauger', 'maugre', 'mayest', 'me', 'meanwhile', 'meanwhiles', 'midst', 'midsts', 'might', 'mights', 'more', 'moreover', 'most', 'mostly', 'much', 'mucher', 'muchest', 'must', 'musth', 'musths', 'musts', 'my', 'myself', 'natheless', 'nathless', 'neath', 'neaths', 'necessarier', 'necessariest', 'necessary', 'neither', 'nethe', 'nethermost', 'never', 'nevertheless', 'nigh', 'nigher', 'nighest', 'nine', 'no', 'nobodies', 'nobody', 'noes', 'none', 'noone', 'nor', 'nos', 'not', 'nothing', 'nothings', 'notwithstanding', 'nowhere', 'nowheres', 'of', 'off', 'offest', 'offs', 'often', 'oftener', 'oftenest', 'oh', 'on', 'one', 'oneself', 'onest', 'ons', 'onto', 'or', 'orer', 'orest', 'other', 'others', 'otherwise', 'otherwiser', 'otherwisest', 'ought', 'oughts', 'our', 'ours', 'ourself', 'ourselves', 'out', 'outed', 'outest', 'outl0', 'outs', 'outside', 'outwith', 'over', 'overall', 'overaller', 'overallest', 'overalls', 'overs', 'own', 'owned', 'owning', 'owns', 'owt', 'paperh16840', 'paperw11900', 'pard', 'pardeftab720', 'particular', 'particularer', 'particularest', 'particularly', 'particulars', 'partightenfactor0', 'per', 'perhaps', 'plaintiff', 'please', 'pleased', 'pleases', 'plenties', 'plenty', 'pre', 'pro', 'probably', 'provide', 'provided', 'provides', 'providing', 'qr', 'qua', 'que', 'quite', 'rath', 'rathe', 'rather', 'rathest', 're', 'really', 'red109', 'red21', 'red255', 'red27', 'regarding', 'relate', 'related', 'relatively', 'res', 'respecting', 'respectively', 'row', 'rtf1', 'said', 'saider', 'saidest', 'same', 'samer', 'sames', 'samest', 'sans', 'sanserif', 'sanserifs', 'sanses', 'saved', 'sayid', 'sayyid', 'seem', 'seemed', 'seeminger', 'seemingest', 'seemings', 'seems', 'send', 'sent', 'senza', 'serious', 'seriouser', 'seriousest', 'seven', 'several', 'severaler', 'severalest', 'shall', 'shalled', 'shalling', 'shalls', 'she', 'should', 'shoulded', 'shoulding', 'shoulds', 'since', 'sine', 'sines', 'sith', 'six', 'sl400', 'so', 'sobeit', 'soer', 'soest', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimer', 'sometimes', 'sometimest', 'somewhat', 'somewhere', 'stop', 'stopped', 'strokec2', 'strokec5', 'strokewidth0', 'such', 'summat', 'sup', 'supped', 'supping', 'sups', 'syn', 'syne', 'taflags1', 'ten', 'than', 'that', 'the', 'thee', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'thener', 'thenest', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'therer', 'therest', 'thereupon', 'these', 'they', 'thine', 'thing', 'things', 'this', 'thises', 'thorough', 'thorougher', 'thoroughest', 'thoroughly', 'those', 'thou', 'though', 'thous', 'thouses', 'three', 'thro', 'through', 'througher', 'throughest', 'throughout', 'thru', 'thruer', 'thruest', 'thus', 'thy', 'thyself', 'till', 'tilled', 'tilling', 'tills', 'to', 'together', 'too', 'toward', 'towarder', 'towardest', 'towards', 'trbrdrl', 'trbrdrr', 'trbrdrt', 'trcbpat3', 'trgaph108', 'trleft', 'trowd', 'two', 'tx1514', 'umpteen', 'under', 'underneath', 'unless', 'unlike', 'unliker', 'unlikest', 'until', 'unto', 'up', 'upon', 'uponed', 'uponing', 'upons', 'upped', 'upping', 'ups', 'us', 'use', 'used', 'usedest', 'username', 'usually', 'various', 'variouser', 'variousest', 'verier', 'veriest', 'versus', 'very', 'via', 'viewh8400', 'viewkind0', 'vieww10800', 'vis', 'viser', 'visest', 'viz', 'vs', 'want', 'was', 'wast', 'we', 'were', 'wert', 'what', 'whatever', 'whateverer', 'whateverest', 'whatsoever', 'whatsoeverer', 'whatsoeverest', 'wheen', 'when', 'whenas', 'whence', 'whencesoever', 'whenever', 'whensoever', 'where', 'whereafter', 'whereas', 'whereby', 'wherefrom', 'wherein', 'whereinto', 'whereof', 'whereon', 'wheresoever', 'whereto', 'whereupon', 'wherever', 'wherewith', 'wherewithal', 'whether', 'which', 'whichever', 'whichsoever', 'while', 'whiles', 'whilst', 'whither', 'whithersoever', 'whoever', 'whomever', 'whose', 'whoso', 'whosoever', 'why', 'will', 'with', 'withal', 'within', 'without', 'would', 'woulded', 'woulding', 'woulds', 'ye', 'yet', 'yon', 'yond', 'yonder', 'you', 'your', 'yours', 'yourself', 'yourselves', 'zillion'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214, 100)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=1,stop_words=stopwords,max_features=100)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ship',\n",
       " 'paring',\n",
       " 'quail',\n",
       " 'sour',\n",
       " 'peking',\n",
       " 'duck',\n",
       " 'dq',\n",
       " 'ranges',\n",
       " 'sesame',\n",
       " 'bitter',\n",
       " 'creaminess',\n",
       " 'brown',\n",
       " 'mochi',\n",
       " 'brother',\n",
       " 'lucille',\n",
       " 'comp',\n",
       " 'ave',\n",
       " 'covered',\n",
       " 'towels',\n",
       " 'blackboard',\n",
       " 'confirmed',\n",
       " 'hurried',\n",
       " 'italy',\n",
       " 'sont',\n",
       " 'paris',\n",
       " 'id',\n",
       " 'shower',\n",
       " 'rag',\n",
       " 'housekeeping',\n",
       " 'papa',\n",
       " 'bake',\n",
       " 'insulting',\n",
       " 'bartenders',\n",
       " 'chloe',\n",
       " 'nature',\n",
       " 'bacchanal',\n",
       " 'pretzels',\n",
       " 'self',\n",
       " 'beers',\n",
       " 'behavior',\n",
       " 'ramsay',\n",
       " 'provided',\n",
       " 'bao',\n",
       " 'shoyu',\n",
       " 'bogo',\n",
       " 'coupon',\n",
       " 'terrace',\n",
       " 'tm',\n",
       " 'forgive',\n",
       " 'daughters',\n",
       " 'bbh',\n",
       " 'beds',\n",
       " 'breading',\n",
       " 'balsamic',\n",
       " 'brat',\n",
       " 'baby',\n",
       " 'mypizza',\n",
       " 'blanco',\n",
       " 'anzio',\n",
       " 'hashbrowns',\n",
       " 'teasers',\n",
       " 'http',\n",
       " 'www',\n",
       " 'com',\n",
       " 'biz_photos',\n",
       " 'lwdnuhcbcnevi',\n",
       " 'nhgewg',\n",
       " 'flavors',\n",
       " 'bone',\n",
       " 'haddock',\n",
       " 'curries',\n",
       " 'hk',\n",
       " 'nachos',\n",
       " 'soupy',\n",
       " 'wally',\n",
       " 'denny',\n",
       " 'wifi',\n",
       " 'connection',\n",
       " 'stores',\n",
       " 'teppanyaki',\n",
       " 'brooklyn',\n",
       " 'capel',\n",
       " 'shank',\n",
       " 'slaw',\n",
       " 'spa',\n",
       " 'amenities',\n",
       " 'maitre',\n",
       " 'strudel',\n",
       " 'paneer',\n",
       " 'faster',\n",
       " 'tooth',\n",
       " 'sub',\n",
       " 'deli',\n",
       " 'jason',\n",
       " 'international',\n",
       " 'ipad',\n",
       " 'buffalo',\n",
       " 'tandoori',\n",
       " 'peruvian',\n",
       " 'porcetta']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['108', 'abaft', 'abafter', 'abaftest', 'about', 'abouter', 'aboutest', 'above', 'abover', 'abovest', 'accordingly', 'aer', 'aest', 'afore', 'after', 'afterer', 'afterest', 'afterward', 'afterwards', 'again', 'against', 'aid', 'ain', 'albeit', 'all', 'aller', 'allest', 'alls', 'allyou', 'almost', 'along', 'alongside', 'already', 'also', 'although', 'always', 'amid', 'amidst', 'among', 'amongst', 'an', 'and', 'andor', 'anear', 'anent', 'another', 'ansi', 'ansicpg1252', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anywhere', 'apart', 'aparter', 'apartest', 'appear', 'appeared', 'appearing', 'appears', 'appropriate', 'appropriated', 'appropriater', 'appropriates', 'appropriatest', 'appropriating', 'are', 'ares', 'around', 'as', 'ases', 'aside', 'asides', 'aslant', 'astraddle', 'astraddler', 'astraddlest', 'astride', 'astrider', 'astridest', 'at', 'athwart', 'atop', 'atween', 'aught', 'aughts', 'available', 'availabler', 'availablest', 'awfully', 'bar', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'becominger', 'becomingest', 'becomings', 'been', 'before', 'beforehand', 'beforehander', 'beforehandest', 'behind', 'behinds', 'being', 'below', 'beneath', 'beside', 'besides', 'better', 'bettered', 'bettering', 'betters', 'between', 'betwixt', 'beyond', 'bist', 'blockquote', 'blue109', 'blue255', 'blue26', 'blue34', 'both', 'brdrnil', 'but', 'buts', 'by', 'byandby', 'c100000', 'c10588', 'c12157', 'c13725', 'c14118', 'c16078', 'c18039', 'c29804', 'c50196', 'can', 'cannot', 'canst', 'cant', 'canted', 'cantest', 'canting', 'cants', 'cell', 'cellx4320', 'cellx8640', 'cer', 'certain', 'certainer', 'certainest', 'cest', 'cf2', 'cf5', 'chez', 'circa', 'clbrdrb', 'clbrdrl', 'clbrdrr', 'clbrdrt', 'clftswidth3', 'clminw1000', 'clmrg', 'clpadl200', 'clpadr200', 'clshdrawnil', 'clvertalt', 'clwwidth1000', 'clwwidth2379', 'co', 'cocoartf1561', 'cocoasubrtf610', 'code', 'colortbl', 'come', 'comeon', 'comeons', 'concerning', 'concerninger', 'concerningest', 'consequently', 'considering', 'consolas', 'could', 'couldst', 'cssrgb', 'cum', 'dday', 'ddays', 'deftab720', 'describe', 'described', 'describes', 'describing', 'despite', 'despited', 'despites', 'despiting', 'did', 'different', 'differenter', 'differentest', 'do', 'doe', 'does', 'doing', 'doings', 'done', 'doner', 'dones', 'donest', 'dos', 'dost', 'doth', 'downs', 'downward', 'downwarder', 'downwardest', 'downwards', 'during', 'each', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'ere', 'et', 'etc', 'even', 'evened', 'evenest', 'evens', 'evenser', 'evensest', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'except', 'excepted', 'excepting', 'excepts', 'exes', 'expandedcolortbl', 'expnd0', 'expndtw0', 'f0', 'fact', 'facts', 'failing', 'failings', 'fcharset0', 'few', 'fewer', 'fewest', 'figupon', 'figuponed', 'figuponing', 'figupons', 'five', 'fnil', 'followthrough', 'fonttbl', 'foo', 'for', 'forby', 'forbye', 'fore', 'forer', 'fores', 'forever', 'former', 'formerer', 'formerest', 'formerly', 'formers', 'fornenst', 'forwhy', 'four', 'fourscore', 'frae', 'from', 'fs', 'fs24', 'further', 'furthered', 'furtherer', 'furtherest', 'furthering', 'furthermore', 'furthers', 'gaph', 'get', 'gets', 'getting', 'go', 'gone', 'good', 'got', 'gotta', 'gotten', 'green109', 'green23', 'green255', 'green31', 'gt', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'had', 'hadst', 'hae', 'hardly', 'has', 'hast', 'hath', 'have', 'haves', 'having', 'he', 'hence', 'her', 'hereafter', 'hereafters', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'hither', 'hitherer', 'hitherest', 'hoo', 'hoos', 'how', 'howbeit', 'howdoyoudo', 'however', 'huh', 'humph', 'idem', 'idemer', 'idemest', 'ie', 'if', 'ifs', 'immediate', 'immediately', 'immediater', 'immediatest', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'indicating', 'info', 'information', 'insofar', 'instead', 'intbl', 'into', 'inward', 'inwarder', 'inwardest', 'inwards', 'is', 'it', 'itap1', 'its', 'itself', 'kerning0', 'lastrow', 'latter', 'latterer', 'latterest', 'latterly', 'latters', 'layabout', 'layabouts', 'less', 'lest', 'li', 'lot', 'lots', 'lotted', 'lotting', 'lt', 'main', 'make', 'many', 'margl1440', 'margr1440', 'mauger', 'maugre', 'mayest', 'me', 'meanwhile', 'meanwhiles', 'midst', 'midsts', 'might', 'mights', 'more', 'moreover', 'most', 'mostly', 'much', 'mucher', 'muchest', 'must', 'musth', 'musths', 'musts', 'my', 'myself', 'natheless', 'nathless', 'neath', 'neaths', 'necessarier', 'necessariest', 'necessary', 'neither', 'nethe', 'nethermost', 'never', 'nevertheless', 'nigh', 'nigher', 'nighest', 'nine', 'no', 'nobodies', 'nobody', 'noes', 'none', 'noone', 'nor', 'nos', 'not', 'nothing', 'nothings', 'notwithstanding', 'nowhere', 'nowheres', 'of', 'off', 'offest', 'offs', 'often', 'oftener', 'oftenest', 'oh', 'on', 'one', 'oneself', 'onest', 'ons', 'onto', 'or', 'orer', 'orest', 'other', 'others', 'otherwise', 'otherwiser', 'otherwisest', 'ought', 'oughts', 'our', 'ours', 'ourself', 'ourselves', 'out', 'outed', 'outest', 'outl0', 'outs', 'outside', 'outwith', 'over', 'overall', 'overaller', 'overallest', 'overalls', 'overs', 'own', 'owned', 'owning', 'owns', 'owt', 'paperh16840', 'paperw11900', 'pard', 'pardeftab720', 'particular', 'particularer', 'particularest', 'particularly', 'particulars', 'partightenfactor0', 'per', 'perhaps', 'plaintiff', 'please', 'pleased', 'pleases', 'plenties', 'plenty', 'pre', 'pro', 'probably', 'provide', 'provided', 'provides', 'providing', 'qr', 'qua', 'que', 'quite', 'rath', 'rathe', 'rather', 'rathest', 're', 'really', 'red109', 'red21', 'red255', 'red27', 'regarding', 'relate', 'related', 'relatively', 'res', 'respecting', 'respectively', 'row', 'rtf1', 'said', 'saider', 'saidest', 'same', 'samer', 'sames', 'samest', 'sans', 'sanserif', 'sanserifs', 'sanses', 'saved', 'sayid', 'sayyid', 'seem', 'seemed', 'seeminger', 'seemingest', 'seemings', 'seems', 'send', 'sent', 'senza', 'serious', 'seriouser', 'seriousest', 'seven', 'several', 'severaler', 'severalest', 'shall', 'shalled', 'shalling', 'shalls', 'she', 'should', 'shoulded', 'shoulding', 'shoulds', 'since', 'sine', 'sines', 'sith', 'six', 'sl400', 'so', 'sobeit', 'soer', 'soest', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimer', 'sometimes', 'sometimest', 'somewhat', 'somewhere', 'stop', 'stopped', 'strokec2', 'strokec5', 'strokewidth0', 'such', 'summat', 'sup', 'supped', 'supping', 'sups', 'syn', 'syne', 'taflags1', 'ten', 'than', 'that', 'the', 'thee', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'thener', 'thenest', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'therer', 'therest', 'thereupon', 'these', 'they', 'thine', 'thing', 'things', 'this', 'thises', 'thorough', 'thorougher', 'thoroughest', 'thoroughly', 'those', 'thou', 'though', 'thous', 'thouses', 'three', 'thro', 'through', 'througher', 'throughest', 'throughout', 'thru', 'thruer', 'thruest', 'thus', 'thy', 'thyself', 'till', 'tilled', 'tilling', 'tills', 'to', 'together', 'too', 'toward', 'towarder', 'towardest', 'towards', 'trbrdrl', 'trbrdrr', 'trbrdrt', 'trcbpat3', 'trgaph108', 'trleft', 'trowd', 'two', 'tx1514', 'umpteen', 'under', 'underneath', 'unless', 'unlike', 'unliker', 'unlikest', 'until', 'unto', 'up', 'upon', 'uponed', 'uponing', 'upons', 'upped', 'upping', 'ups', 'us', 'use', 'used', 'usedest', 'username', 'usually', 'various', 'variouser', 'variousest', 'verier', 'veriest', 'versus', 'very', 'via', 'viewh8400', 'viewkind0', 'vieww10800', 'vis', 'viser', 'visest', 'viz', 'vs', 'want', 'was', 'wast', 'we', 'were', 'wert', 'what', 'whatever', 'whateverer', 'whateverest', 'whatsoever', 'whatsoeverer', 'whatsoeverest', 'wheen', 'when', 'whenas', 'whence', 'whencesoever', 'whenever', 'whensoever', 'where', 'whereafter', 'whereas', 'whereby', 'wherefrom', 'wherein', 'whereinto', 'whereof', 'whereon', 'wheresoever', 'whereto', 'whereupon', 'wherever', 'wherewith', 'wherewithal', 'whether', 'which', 'whichever', 'whichsoever', 'while', 'whiles', 'whilst', 'whither', 'whithersoever', 'whoever', 'whomever', 'whose', 'whoso', 'whosoever', 'why', 'will', 'with', 'withal', 'within', 'without', 'would', 'woulded', 'woulding', 'woulds', 'ye', 'yet', 'yon', 'yond', 'yonder', 'you', 'your', 'yours', 'yourself', 'yourselves', 'zillion'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#get the text column\n",
    "docs=zero[\"text\"].tolist()\n",
    "#create a vocabulary of words,\n",
    "#ignore words that appear in 85% of documents,\n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=1, stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 100)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=1,stop_words=stopwords,max_features=100)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neo',\n",
       " 'matcha',\n",
       " 'raspberry',\n",
       " 'latilla',\n",
       " 'reflective',\n",
       " 'lao',\n",
       " 'levetto',\n",
       " 'memory',\n",
       " 'asu',\n",
       " 'nana']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1=['sour','peking','bitter','creaminess','planted','chilis',\n",
    "          'lucille','misunderstanding','mistakes','hurried','less',\n",
    "          'housekeeping','bake','casinos','bacchanal','leek','hells',\n",
    "          'terrace','tm','brat','wifi connection','rescue','amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0=['matcha','raspberry','memory', 'cafeteria', 'plateau',\n",
    " 'church','numerous','flavourful', 'fuzzy','fashion','definetly',\n",
    " 'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
